\documentclass[letterpaper]{article}
\usepackage{natbib,alifexi}

\title{Project Computational Game Theory\\Evolution of All-or-None Strategies in Repeated Public Goods Dilemmas}
\author{Ruben Vereecken, Yoni Pervolarakis \and Laurens Hernalsteen \\
\mbox{}\\Vrije Universiteit Brussel \\Pleinlaan 2, \\B-1050 Brussels, BELGIUM\\
{\texttt{\{rvereeck,ypervola,lhernals\}@vub.ac.be}}}


\begin{document}
\maketitle

\begin{abstract}
Engaging in repeated group interactions such as \textit{Public Good Games}  (\textbf{PGG}), groups of individuals may contribute to a common pool and subsequently share their resources. In this paper we will recreate the research and results from the paper  \textit{Evolution of All-Or-None Strategies in Repeated Public Goods Dilemmas}  \citep{project}. Studying evolutionary dynamics, where individuals behave on what they observed in the previous round, the simple \textit{All-Or-None} \textbf{(AON)} strategy  will emerge. AON consists of cooperating only after an unanimous group choice. We prove the robustness of this strategy by using different group sizes and error rates
\textit{\textbf{Short summary of results....}}


\end{abstract}

\section{Introduction}
When studying \textit{Public Good Games}  (\textbf{PGG}), such as \textit{N-person Prisoner's Dilemma}  (\textbf{NPD}), social dilemma's arise where self-serving behavior is worse than collective behavior \citep{kollock1998social}. These problems can be found in economics as well in biology.
Without additional mechanisms such as risk of future loss \citep{santos2011risk}, institutions who deal with free-riders who choose not to contribute \citep{vasconcelos2013bottom,sigmund2010social}, thresholds that must be surpassed before collecting action can be successful \citep{pacheco2011evolutionary}, a network of interactions or social diversity \citep{wang2013interdependent,santos2008social}, punishment \citep{fehr2002altruistic,brandt2006punishing} or voluntary participation \citep{hauert2002volunteering} there is a possibility that populations will fall into a tragedy of the commons \citep{hardin1968tragedy}.
Collective action problems often involve in repeated actions between individuals of the same group \citep{boyd1988evolution}. Real life examples can be found in world leaders trying to cooperate in changing the climate problems \citep{milinski2008collective,barrett2012climate}, the monetary crisis \citep{jacquet2001economic} and even in anarchies \citep{axelrod1985achieving}. This leads to the question whether direct reciprocity can escape the tragedy of the commons. If we subdivide this question, it is difficult to find to whom one should reciprocate in repeated N-player interactions. Direct reciprocity has been generalized for (\textbf{PGG}) where individuals of group size N only cooperate if there are at least M $(0<=M<=N)$ cooperators in the previous round \citep{van2012emergence,kurokawa2009emergence}. Generalized reciprocators provide a generalization of the \textit{Tit For Tat}  (\textbf{TFT}) strategy, but they constitute a small set of all individual strategies.
In this research exploration of different strategies will be explored, where individuals may adopt a different strategy when playing PGG on the condition that their actions are based on the behavior of the group in the previous round.
\textit{\textbf{more??}}

\section{Methods}
Let us consider a finite and will-mixed population $Z$, with only cooperators and defectors, who randomly form groups of size $N$ and play the repeated version of \textbf{NPD}. In every round individuals can either cooperate (\textbf{C}) by contributing an amount $c$ to a public pool or defect (\textbf{D}). The sum contributions of a group are per round are multiplied by an enhancement factor $F$ and will become a public good to the group. This will equally be divided amongst  the $N$ individuals. In each round defectors will achieve a payoff of $\pi_{D}= \frac{kFc}{N}$  and cooperators will achieve $\pi_{C}=\pi_{D}-c$ where $k$ is the number of cooperation in that round. In this model \textbf{PGG} will have an undetermined amount of rounds, where at the end of every round another round might take place with probability $w$. This leads to an average amount of rounds, denoted as $m$, where $m= (1-w)^{-1}$. Individuals decide in each round, except the first round, to cooperate or not based on the total amount of contributions in the previous round.
\textit{\textbf{...bitshizzle...}}
The Fermi update rule \citep{traulsen2006stochastic,grujic2014comparative} is used each round to revise the strategies of the individuals.
In each round a random individual $A$ will be chosen, with its strategy $S_{A}$ and fitness $f_{_f{A}}$. The fitness of a strategy is the average payoff over all rounds for that strategy. Individual $A$ can change its strategy through $i)$ mutating with probability $\mu$ or $ii)$ by imitating a random individual $B$ with probability $(1-\mu)(1+exp[-\beta(f_{_S{A}}-f_{_S{B}})])^{-1}$, where $\beta$ is the intensity of selection.
In each round after choosing to cooperate or defect, an individual may choose the opposite behavior with a probability of $\epsilon$.



\section{Results}


\begin{figure}[!htb]
\begin{center}
\includegraphics[width=3in,angle=0]{img/CooperationFrac.png}
\caption{Cooperation fraction throughout time (100 sims).}
\label{fig1}
\end{center}
\end{figure}

% In Fig.~\ref{fig2}

\section{Discussion}
Something something

\section{Acknowledgments}

Help from Fl\'{a}vio L. Pinheiro....


\footnotesize
\bibliographystyle{apalike}
\bibliography{biblio}


\end{document}
